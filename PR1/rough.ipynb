{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.utils import check_array\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(point, centroid):\n",
    "    return np.sqrt(np.sum((point - centroid) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading an image (replace filename if you want):\n",
    "image_path = 'giraffe.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Reducing the size of the image, so that DBSCAN runs in a reasonable amount of time:\n",
    "# small_image is 0.5x the size of the original. You may change this value.\n",
    "image = cv2.resize(image, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "height, width, _ = image.shape\n",
    "pixel_data = image.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 200, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26800, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kmeans parameters\n",
    "k = 2\n",
    "max_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_points = np.random.rand(50,3) * 10\n",
    "data_points = pixel_data\n",
    "data_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "centroids = data_points[np.random.choice(data_points.shape[0],k,replace=False)]\n",
    "labels = []\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    # print(f\"Iteration {iteration}, Centroids = {centroids}\")\n",
    "    clusters = [[] for _ in range(k)]\n",
    "    test_labels = []\n",
    "    for point in data_points:\n",
    "        distances = [euclidean_distance(point, centroid) for centroid in centroids]\n",
    "        cluster_index = np.argmin(distances)\n",
    "        clusters[cluster_index].append(point)\n",
    "        test_labels.append(cluster_index)\n",
    "        # print(f'Point = {point}, distances = {distances}, cluster_index = {cluster_index}')\n",
    "    # print(f'clusters = {clusters}')\n",
    "\n",
    "    new_centroids = []\n",
    "    for cluster in clusters:\n",
    "        if cluster:\n",
    "            new_centroid = np.mean(cluster, axis=0)\n",
    "            new_centroids.append(new_centroid)\n",
    "        else:\n",
    "            new_centroids.append(centroids[len(new_centroids)])\n",
    "\n",
    "    new_centroids = np.array(new_centroids)\n",
    "\n",
    "    if np.allclose(centroids, new_centroids):\n",
    "        print(f'Converged after {iteration + 1} iterations')\n",
    "        break\n",
    "\n",
    "    centroids = new_centroids\n",
    "    labels = test_labels\n",
    "    # print('-'*25)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.count(1) + labels.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(clusters)):\n",
    "    print(f'Cluster with index {index} = {clusters[index]}, Total values = {len(clusters[index])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [np.array(cluster) for cluster in clusters]\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, cluster in enumerate(clusters):\n",
    "    print(index, cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for point in data_points:\n",
    "    for label, cluster in enumerate(clusters):\n",
    "        if point in cluster:\n",
    "            labels.append(label)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26800, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DBSCAN\n",
    "# Setting hyperparameter(s):\n",
    "eps = 5\n",
    "min_pts = 30\n",
    "\n",
    "#Load data\n",
    "# data_points = np.random.randint(low=0, high=255, size=(1000,3))\n",
    "data_points = pixel_data\n",
    "data_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(min_samples=min_pts,eps=eps,algorithm='brute')\n",
    "dbscan_labels = dbscan.fit_predict(data_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-1: 9139,\n",
       "         0: 6062,\n",
       "         2: 2991,\n",
       "         13: 2610,\n",
       "         3: 1913,\n",
       "         8: 1758,\n",
       "         10: 960,\n",
       "         5: 233,\n",
       "         19: 100,\n",
       "         4: 97,\n",
       "         24: 86,\n",
       "         26: 86,\n",
       "         14: 81,\n",
       "         1: 74,\n",
       "         20: 70,\n",
       "         15: 59,\n",
       "         17: 55,\n",
       "         6: 55,\n",
       "         21: 52,\n",
       "         9: 39,\n",
       "         7: 38,\n",
       "         22: 37,\n",
       "         16: 36,\n",
       "         25: 32,\n",
       "         27: 31,\n",
       "         12: 30,\n",
       "         11: 30,\n",
       "         18: 26,\n",
       "         23: 20})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(dbscan_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDBSCAN:\n",
    "    def __init__(self, eps=0.5, min_samples=5, metric='euclidean'):\n",
    "        \"\"\"\n",
    "        Creates an instance of CustomDBSCAN.\n",
    "        :param min_samples: Equivalent to minPts. Minimum amount of neighbors of a core object.\n",
    "        :param eps: Short for epsilon. Radius of considered circle around a possible core object.\n",
    "        :param metric: Used metric for measuring distances.\n",
    "        \"\"\"\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "        self.metric = metric\n",
    "        self.labels_ = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y=None):\n",
    "        \"\"\"\n",
    "        This is the main clustering method of the CustomDBSCAN class, which means that this is one of the methods you\n",
    "        will have to complete/implement. The method performs the clustering on vectors given in X. It is important that\n",
    "        this method saves the determined labels (=mapping of vectors to clusters) in the \"self.labels_\" attribute! As\n",
    "        long as it does this, you may change the content of this method completely and/or encapsulate the necessary\n",
    "        mechanisms in additional functions.\n",
    "        :param X: Array that contains the input feature vectors\n",
    "        :param y: Unused\n",
    "        :return: Returns the clustering object itself.\n",
    "        \"\"\"\n",
    "        # Input validation:\n",
    "        X = check_array(X, accept_sparse='csr')\n",
    "\n",
    "        \"\"\"\n",
    "            Notes:\n",
    "            -------\n",
    "            label info\n",
    "\n",
    "            0 - Unvisited Point\n",
    "            -1 - Noise Point\n",
    "            n - assigned to cluster 'n'\n",
    "        \"\"\"\n",
    "\n",
    "        # Determination of labels:\n",
    "        self.labels_ = None  # TODO: Implement your solution here!\n",
    "        self.labels_ = [0] * X.shape[0]\n",
    "\n",
    "        cluster_id = 0\n",
    "\n",
    "        n = X.shape[0]\n",
    "\n",
    "        for index in range(n):\n",
    "            object = X[index]\n",
    "            if self.labels_[index] == 0:\n",
    "                print(f'Exploring object {object} at index {index}') \n",
    "                self._expand_cluster(X,index,cluster_id,self.eps,self.min_samples)\n",
    "                cluster_id += 1\n",
    "            \n",
    "\n",
    "        return self\n",
    "\n",
    "    def fit_predict(self, X: np.ndarray, y=None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calls fit() and immediately returns the labels. See fit() for parameter information.\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.labels_\n",
    "    \n",
    "    def _get_seeds(self,X,obj_index,eps):\n",
    "        seeds = []\n",
    "        for index, point in enumerate(X):\n",
    "            if euclidean_distance(X[obj_index],point) <= eps:\n",
    "                seeds.append(index)\n",
    "        return seeds\n",
    "    \n",
    "    def _expand_cluster(self,X,obj_index,cluster_id,eps,min_samples):\n",
    "        seeds = self._get_seeds(X,obj_index,eps)\n",
    "        print(seeds)\n",
    "\n",
    "        if len(seeds) < min_samples:\n",
    "            self.labels_[obj_index] = -1 # Mark as noise point\n",
    "        else:\n",
    "            for seed_index, seed in enumerate(seeds):\n",
    "                self.labels_[seed_index] = cluster_id # Mark/Add all seeds around that core point to that cluster\n",
    "            seeds.remove(obj_index)\n",
    "            \n",
    "            seed_index = 0\n",
    "            while seed_index < len(seeds):\n",
    "                new_seeds = self._get_seeds(X,seed_index,eps)\n",
    "                if len(new_seeds) >= min_samples:\n",
    "                    for neighbour_index in range(len(new_seeds)):\n",
    "                        neighbour = new_seeds[neighbour_index]\n",
    "                        if self.labels_[neighbour] in [-1,0]:\n",
    "                            if self.labels_[neighbour] == 0:\n",
    "                                seeds.append(neighbour)\n",
    "                            self.labels_[neighbour] = cluster_id\n",
    "                seeds.remove(neighbour)\n",
    "                seed_index += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring object [185 162 124] at index 0\n",
      "[0, 1]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m customdbscan \u001b[38;5;241m=\u001b[39m CustomDBSCAN(eps\u001b[38;5;241m=\u001b[39meps,min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m customdbscan_labels \u001b[38;5;241m=\u001b[39m customdbscan\u001b[38;5;241m.\u001b[39mfit_predict(X\u001b[38;5;241m=\u001b[39mpixel_data[:\u001b[38;5;241m10\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(customdbscan_labels.shape)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(Counter(customdbscan_labels))\n",
      "Cell \u001b[0;32mIn[27], line 60\u001b[0m, in \u001b[0;36mCustomDBSCAN.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: np\u001b[38;5;241m.\u001b[39mndarray, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    Calls fit() and immediately returns the labels. See fit() for parameter information.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "Cell \u001b[0;32mIn[27], line 50\u001b[0m, in \u001b[0;36mCustomDBSCAN.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_[index] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExploring object \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mobject\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m---> 50\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_cluster(X,index,cluster_id,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples)\n\u001b[1;32m     51\u001b[0m         cluster_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "Cell \u001b[0;32mIn[27], line 83\u001b[0m, in \u001b[0;36mCustomDBSCAN._expand_cluster\u001b[0;34m(self, X, obj_index, cluster_id, eps, min_samples)\u001b[0m\n\u001b[1;32m     81\u001b[0m seed_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m seed_index \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(seeds):\n\u001b[0;32m---> 83\u001b[0m     new_seeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_seeds(X,seed_index,eps)\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_seeds) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m min_samples:\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m neighbour_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(new_seeds)):\n",
      "Cell \u001b[0;32mIn[27], line 66\u001b[0m, in \u001b[0;36mCustomDBSCAN._get_seeds\u001b[0;34m(self, X, obj_index, eps)\u001b[0m\n\u001b[1;32m     64\u001b[0m seeds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, point \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X):\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m euclidean_distance(X[obj_index],point) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m eps:\n\u001b[1;32m     67\u001b[0m         seeds\u001b[38;5;241m.\u001b[39mappend(index)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seeds\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 0 with size 10"
     ]
    }
   ],
   "source": [
    "customdbscan = CustomDBSCAN(eps=eps,min_samples=2)\n",
    "customdbscan_labels = customdbscan.fit_predict(X=pixel_data[:10])\n",
    "# print(customdbscan_labels.shape)\n",
    "print(Counter(customdbscan_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbours(point_index,data_points=data_points,radius=eps):\n",
    "    neighbours = []\n",
    "    for index, point in enumerate(data_points):\n",
    "        if euclidean_distance(data_points[point_index], point) <= radius:\n",
    "            neighbours.append(index)\n",
    "    \n",
    "    return neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_cluster(index, neighbours, cluster_id):\n",
    "    i = 0\n",
    "    while i < len(neighbours):\n",
    "        neighbour = neighbours[i]\n",
    "        if labels[neighbour] == -1: # already a neighbour point and marked as noise, so it'll be masked as leaf point and added to cluster\n",
    "            labels[neighbour] = cluster_id\n",
    "        elif labels[neighbour] == 0: # unvisited point\n",
    "            labels[neighbour] = cluster_id\n",
    "            new_neighbours = get_neighbours(neighbour)\n",
    "            if len(new_neighbours) >= min_pts:\n",
    "                neighbours  = neighbours + new_neighbours # add the new neighbours into the old neighbours\n",
    "        i += 1\n",
    "        print(f'{i}, Remaining Neighbous to explore : {len(neighbours)}, Clusters so far = {Counter(labels)}')\n",
    "    # print(f'Clusters so far = {Counter(labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label information\n",
    "# -1 = Noise Point\n",
    "# 0 = Not visited yet\n",
    "# n = already visited and assigned to cluster n\n",
    "\n",
    "labels = np.full(data_points.shape[0],0)\n",
    "cluster_id = 0\n",
    "\n",
    "# Algo Start\n",
    "for index, point in enumerate(data_points):\n",
    "    print(f'Point = {point}, Clusters = {Counter(labels)}')\n",
    "    if labels[index] == 0: \n",
    "        neighbours = get_neighbours(index)\n",
    "        if len(neighbours) < min_pts:\n",
    "            labels[index] = -1 # mark as noise point\n",
    "        else:\n",
    "            cluster_id += 1\n",
    "            labels[index] = cluster_id # assign the point ot cluster\n",
    "            # print(Counter(labels))\n",
    "            # Grow Cluster\n",
    "            # neighbours, cluster id, point\n",
    "            expand_cluster(index,neighbours,cluster_id)\n",
    "    # print(Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def custom_dbscan(D, eps, MinPts):\n",
    "    '''\n",
    "    Cluster the dataset `D` using the DBSCAN algorithm.\n",
    "    \n",
    "    dbscan takes a dataset `D` (a list of vectors), a threshold distance\n",
    "    `eps`, and a required number of points `MinPts`.\n",
    "    \n",
    "    It will return a list of cluster labels. The label -1 means noise, and then\n",
    "    the clusters are numbered starting from 1.\n",
    "    '''\n",
    " \n",
    "    # This list will hold the final cluster assignment for each point in D.\n",
    "    # There are two reserved values:\n",
    "    #    -1 - Indicates a noise point\n",
    "    #     0 - Means the point hasn't been considered yet.\n",
    "    # Initially all labels are 0.    \n",
    "    labels = [0]*len(D)\n",
    "\n",
    "    # C is the ID of the current cluster.    \n",
    "    C = 0\n",
    "    \n",
    "    # This outer loop is just responsible for picking new seed points--a point\n",
    "    # from which to grow a new cluster.\n",
    "    # Once a valid seed point is found, a new cluster is created, and the \n",
    "    # cluster growth is all handled by the 'expandCluster' routine.\n",
    "    \n",
    "    # For each point P in the Dataset D...\n",
    "    # ('P' is the index of the datapoint, rather than the datapoint itself.)\n",
    "    for P in range(0, len(D)):\n",
    "    \n",
    "        # Only points that have not already been claimed can be picked as new \n",
    "        # seed points.    \n",
    "        # If the point's label is not 0, continue to the next point.\n",
    "        if not (labels[P] == 0):\n",
    "           continue\n",
    "        \n",
    "        # Find all of P's neighboring points.\n",
    "        NeighborPts = region_query(D, P, eps)\n",
    "        \n",
    "        # If the number is below MinPts, this point is noise. \n",
    "        # This is the only condition under which a point is labeled \n",
    "        # NOISE--when it's not a valid seed point. A NOISE point may later \n",
    "        # be picked up by another cluster as a boundary point (this is the only\n",
    "        # condition under which a cluster label can change--from NOISE to \n",
    "        # something else).\n",
    "        if len(NeighborPts) < MinPts:\n",
    "            labels[P] = -1\n",
    "        # Otherwise, if there are at least MinPts nearby, use this point as the \n",
    "        # seed for a new cluster.    \n",
    "        else: \n",
    "           C += 1\n",
    "           grow_cluster(D, labels, P, NeighborPts, C, eps, MinPts)\n",
    "        print('-'*50)\n",
    "    \n",
    "    # All data has been clustered!\n",
    "    return labels\n",
    "\n",
    "\n",
    "def grow_cluster(D, labels, P, NeighborPts, C, eps, MinPts):\n",
    "    '''\n",
    "    Grow a new cluster with label `C` from the seed point `P`.\n",
    "    \n",
    "    This function searches through the dataset to find all points that belong\n",
    "    to this new cluster. When this function returns, cluster `C` is complete.\n",
    "    \n",
    "    Parameters:\n",
    "      `D`      - The dataset (a list of vectors)\n",
    "      `labels` - List storing the cluster labels for all dataset points\n",
    "      `P`      - Index of the seed point for this new cluster\n",
    "      `NeighborPts` - All of the neighbors of `P`\n",
    "      `C`      - The label for this new cluster.  \n",
    "      `eps`    - Threshold distance\n",
    "      `MinPts` - Minimum required number of neighbors\n",
    "    '''\n",
    "\n",
    "    # Assign the cluster label to the seed point.\n",
    "    labels[P] = C\n",
    "    \n",
    "    # Look at each neighbor of P (neighbors are referred to as Pn). \n",
    "    # NeighborPts will be used as a FIFO queue of points to search--that is, it\n",
    "    # will grow as we discover new branch points for the cluster. The FIFO\n",
    "    # behavior is accomplished by using a while-loop rather than a for-loop.\n",
    "    # In NeighborPts, the points are represented by their index in the original\n",
    "    # dataset.\n",
    "    i = 0\n",
    "    while i < len(NeighborPts):    \n",
    "        \n",
    "        # Get the next point from the queue.        \n",
    "        Pn = NeighborPts[i]\n",
    "       \n",
    "        # If Pn was labelled NOISE during the seed search, then we\n",
    "        # know it's not a branch point (it doesn't have enough neighbors), so\n",
    "        # make it a leaf point of cluster C and move on.\n",
    "        if labels[Pn] == -1:\n",
    "           labels[Pn] = C\n",
    "        \n",
    "        # Otherwise, if Pn isn't already claimed, claim it as part of C.\n",
    "        elif labels[Pn] == 0:\n",
    "            # Add Pn to cluster C (Assign cluster label C).\n",
    "            labels[Pn] = C\n",
    "            \n",
    "            # Find all the neighbors of Pn\n",
    "            PnNeighborPts = region_query(D, Pn, eps)\n",
    "            \n",
    "            # If Pn has at least MinPts neighbors, it's a branch point!\n",
    "            # Add all of its neighbors to the FIFO queue to be searched. \n",
    "            if len(PnNeighborPts) >= MinPts:\n",
    "                NeighborPts = NeighborPts + PnNeighborPts\n",
    "            # If Pn *doesn't* have enough neighbors, then it's a leaf point.\n",
    "            # Don't queue up it's neighbors as expansion points.\n",
    "            #else:\n",
    "                # Do nothing                \n",
    "                #NeighborPts = NeighborPts               \n",
    "        \n",
    "        # Advance to the next point in the FIFO queue.\n",
    "        print(f'{i}, Remaining Neighbous to explore : {len(NeighborPts)}, Clusters so far = {Counter(labels)}')\n",
    "        i += 1\n",
    "\n",
    "    \n",
    "    # We've finished growing cluster C!\n",
    "\n",
    "\n",
    "def region_query(D, P, eps):\n",
    "    '''\n",
    "    Find all points in dataset `D` within distance `eps` of point `P`.\n",
    "    \n",
    "    This function calculates the distance between a point P and every other \n",
    "    point in the dataset, and then returns only those points which are within a\n",
    "    threshold distance `eps`.\n",
    "    '''\n",
    "    neighbors = []\n",
    "    \n",
    "    # For each point in the dataset...\n",
    "    for Pn in range(0, len(D)):\n",
    "        \n",
    "        # If the distance is below the threshold, add it to the neighbors list.\n",
    "        if numpy.linalg.norm(D[P] - D[Pn]) < eps:\n",
    "           neighbors.append(Pn)\n",
    "            \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = custom_dbscan(D=data_points,eps=eps,MinPts=min_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
